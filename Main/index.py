# from email.mime import image
import streamlit as st
import time
import numpy as np
import pandas as pd
from PIL import Image
import codecs
import os.path as osp
from zipfile import ZipFile
from io import BytesIO

import sys
sys.path.append(osp.join(osp.dirname(__file__), '..'))
from TransE import TransE_pytorch
from TransR import TransR_pytorch
from TransH import TransH_pytorch
from TransD import TransD_pytorch
from utils import *
from introduction import *

# global variable
# è®­ç»ƒç”¨çš„æ–‡ä»¶
trainTriples = None
entityToId = None
relationToId = None
validTriples = None

# å®ä½“å’Œå…³ç³»embeddingç»“æœå†™å…¥çš„æ–‡ä»¶è·¯å¾„
entityEmbRes = None
relationEmbRes = None

# æµ‹è¯•é˜¶æ®µç”¨çš„æ–‡ä»¶
testTriples = None

# ç»“æœå±•ç¤ºç”¨çš„æ–‡ä»¶
csv_filePath = None     # TransE
fig_path = None         # æŸå¤±å‡½æ•°å›¾ç‰‡

raw_hit_10 = 0
raw_mean_rank = 0
filtered_hit_10 = 0
filtered_mean_rank = 0

# ä¸€ã€å‚æ•°å˜åŒ–æƒ…å†µå±•ç¤ºå‡½æ•°
def params_show(file):
    st.write("ä¸€ã€ç®—æ³•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‚æ•°å±•ç¤ºï¼š")
    _df = pd.read_csv(csv_filePath, index_col=0)
    st.dataframe(data=_df, width=1000, height=400)

# äºŒã€æŸå¤±å‡½æ•°å˜åŒ–æƒ…å†µå±•ç¤ºå‡½æ•°
def loss_plot(file):
    with st.container():
        st.write("äºŒã€æµ‹è¯•é›†å’Œè®­ç»ƒé›†çš„æŸå¤±å‡½æ•°å˜åŒ–æƒ…å†µï¼š")
        image = Image.open(fig_path)
        st.image(image, caption="æŸå¤±å‡½æ•°å˜åŒ–æƒ…å†µ")

# ä¸‰ã€æµ‹è¯•é›†ä¸Šçš„æŒ‡æ ‡å±•ç¤º
def test_metric_show(var1,var2,var3,var4):
    with st.container():
        st.write("ä¸‰ã€åœ¨æµ‹è¯•é›†ä¸Šçš„æŒ‡æ ‡å±•ç¤ºï¼š")
        with st.expander("â„¹ï¸ æŒ‡æ ‡è¯´æ˜"):
            st.info('Mean Rankï¼šæ­£ç¡®å®ä½“çš„å¹³å‡æ’åï¼Œè¯¥å€¼è¶Šå°è¶Šå¥½;\n\n\n\n\n\n\nhit@10ï¼šæ­£ç¡®å®ä½“æ’ååœ¨å‰10çš„æ¯”ä¾‹ï¼Œè¯¥å€¼è¶Šå¤§è¶Šå¥½ï¼›')
        st.write(pd.DataFrame({
            "mean_rank(raw)": [var1],
            "hit@10(raw)": [var2],
            "mean_rank(filtered)": [var3],
            "hit@10(filtered)": [var4]
        }))

# å‹ç¼©åŒ…ä¸‹è½½
def zip_download_button(zip_file):
    with st.container():
        st.write("å››ã€è®­ç»ƒå®Œæˆçš„ç»“æœä¸‹è½½")
        with open(zip_file, "rb") as f:
            return st.download_button(
                label="âœ¨ ç»“æœä¸‹è½½",
                data=f,
                file_name="all_results.zip",
                mime="application/zip"
            )

st.set_page_config(
   page_title="Trans-Series Knowledge Graph Embedding",
   page_icon="ğŸˆ",
   layout="wide",
   initial_sidebar_state="expanded",
)

# set app layout width
def _max_width_():
    max_width_str = f"max-width: 1400px;"
    st.markdown(
        f"""
    <style>
    .reportview-container .main .block-container{{
        {max_width_str}
    }}
    </style>    
    """,
        unsafe_allow_html=True,
    )
_max_width_()

c30, c31, c32 = st.columns([2.5, 1, 3])

with c30:
    image = Image.open(r'D:\Codes\ç½‘å®‰ç»¼åˆå®éªŒ\Main\logo.png')
    st.image(image, width=400)
    st.header("")

with c32:
    st.header("")
    st.header("")
    st.header("")
    st.text("")
    st.text("")
    st.header("")

st.markdown("## **Introduction**")

with st.expander("â„¹ï¸ - About this app"):
    st.write(
        """     
1.  åŸºäºTranslationçš„çŸ¥è¯†å›¾è°±è¡¨ç¤ºå­¦ä¹ ç»å…¸æ¨¡å‹ï¼ŒåŒ…å«TransEã€TransHã€TransRã€TransD;
2.  å·¦ä¾§å‚æ•°è®¾ç½®æ è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€æ•°æ®é›†é€‰æ‹©å’Œè®­ç»ƒå‚æ•°è®¾ç½®;
3.  å³ä¾§åŒºåŸŸä¼šæ˜¾ç¤ºå¦‚ä¸‹ç›¸å…³ä¿¡æ¯:
-   æ‰€é€‰ç®—æ³•çš„ä¸»è¦æ€æƒ³
-   æ‰€é€‰ç®—æ³•çš„æ ¸å¿ƒä»£ç 
-   æ‰€é€‰æ•°æ®é›†çš„åŸºæœ¬æƒ…å†µ
-   è®­ç»ƒè¿‡ç¨‹çš„æŸå¤±å‡½æ•°å¯è§†åŒ–
-   åœ¨æµ‹è¯•é›†ä¸Šçš„æŒ‡æ ‡å±•ç¤º
-   ç»“æœä¸‹è½½
	    """
)

    st.markdown("")

with st.expander("ğŸ”† Coming soon!", expanded=False):
    st.write(
        """  
-   Add more knowledge graph embedding models.
-   Add more available dataset.
-   Allow uploading user's personal dataset.

	    """
    )
    st.markdown("")

st.markdown("")

# å·¦ä¾§ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("# â„¹ï¸å‚æ•°è®¾ç½®")
    # st.header("çŸ¥è¯†å›¾è°±Transç³»åˆ—è¡¨ç¤ºå­¦ä¹ ç®—æ³•")
    with st.form("params_form"):
        # radioå•é€‰æ¡†ä¼šè¿”å›æ‰€é€‰æ‹©çš„é€‰é¡¹å†…å®¹
        st.write("1.ç®—æ³•é€‰æ‹©")
        algorithm_selection = st.radio(
            "é€‰æ‹©è¦ä½¿ç”¨çš„ç®—æ³•ï¼š",
            ('TransE',"TransH","TransR","TransD"),
            help="ç‚¹å‡»åº•éƒ¨è¿è¡ŒæŒ‰é’®åï¼Œä¼šåœ¨å³ä¾§åŒºåŸŸå±•ç¤ºæ‰€é€‰ç®—æ³•çš„ç›¸å…³ä»‹ç»"
        )
        st.write("2.æ•°æ®é›†é€‰æ‹©")
        dataset_selection = st.radio(
            "é€‰æ‹©é»˜è®¤æä¾›çš„æ•°æ®é›†ï¼š",
            ('FreeBase15K', "WordNet18", "Countries","DBpedia50","WN18RR","UMLS"),
            help="ç‚¹å‡»åº•éƒ¨è¿è¡ŒæŒ‰é’®åï¼Œä¼šåœ¨å³ä¾§åŒºåŸŸå±•ç¤ºæ‰€é€‰æ•°æ®é›†çš„ç›¸å…³ä»‹ç»"
        )

        # number_inputæ¡†ä¼šè¿”å›è¾“å…¥çš„æ•°å­—
        st.write("3.Embeddingç»´åº¦è®¾ç½®")
        embedding_selection = st.number_input(
            label="è¯·è®¾ç½®embeddingç»´åº¦"
        )

        st.write("4.å­¦ä¹ ç‡è®¾ç½®")
        lr_selection = st.number_input(
            label="è¯·è®¾ç½®ç®—æ³•å­¦ä¹ ç‡",
            min_value=0.01
        )

        st.write("5.epochesè®¾ç½®")
        epoch_selection = st.number_input(
            label="è¯·è®¾ç½®epochçš„æ•°é‡"
        )

        st.write("6.è®­ç»ƒå®Œæˆåæ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæµ‹è¯•")
        test_flag = st.selectbox(
            label=" ",
            options =(True,False),
            help="NOTE: ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´!"
        )

        # ç”¨æˆ·é€‰æ‹©çš„å‚æ•°åˆ—è¡¨
        # åŒæ—¶å¯¹è¾“å…¥çš„å˜é‡ç±»å‹è¿›è¡Œå¿…è¦è½¬æ¢
        para_list = [
            algorithm_selection,
            dataset_selection,
            int(embedding_selection),
            lr_selection,
            int(epoch_selection),
            test_flag
        ]
        st.info("ç‚¹å‡»å¼€å§‹è¿è¡ŒæŒ‰é’®å‰è¯·å†ç¡®è®¤ä¸€ä¸‹æ‰€é€‰å‚æ•°å™¢~")
        submitted = st.form_submit_button("å¼€å§‹è¿è¡Œ",help="è¯·æ³¨æ„ç¡®è®¤å‚æ•°")


# å³ä¾§ä¸»å†…å®¹åŒºåŸŸ
st.markdown("## **Relative Information**")

# ç‚¹å‡»submitæŒ‰é’®ä¹‹åçš„æ“ä½œ
if submitted:
    # è·å–å„ä¸ªå‚æ•°å€¼ï¼Œæ–¹ä¾¿åç»­ä¼ å…¥æ¨¡å‹
    alg = para_list[0]
    dataset = para_list[1]
    embedding_size = para_list[2]
    lr_rate = para_list[3]
    epoch_nums = para_list[4]
    testFlage = para_list[-1]

    with st.expander("1.å‚æ•°è®¾ç½®æƒ…å†µ"):
        st.info(f"ï¼ˆ1ï¼‰ä½¿ç”¨ç®—æ³•ï¼š{alg}\n\nï¼ˆ2ï¼‰é€‰ç”¨æ•°æ®é›†ï¼š{dataset}\n\nï¼ˆ3ï¼‰åµŒå…¥ç»´åº¦ï¼š{embedding_size}\n\nï¼ˆ4ï¼‰è®¾ç½®çš„å­¦ä¹ ç‡ï¼š{lr_rate}\n\nï¼ˆ5ï¼‰è®¾ç½®çš„è¿­ä»£è½®æ•°ï¼š{epoch_nums}")

    alg_introduction(alg)
    dataset_introduction(dataset)
    alg_sourcecode_show(alg)

# å¦‚æœæ˜¯TransEç®—æ³•
    if algorithm_selection == "TransE":
        data_paths = ds_selection(dataset)
        batch_size = batchSize_selection(dataset)
        trainTriples, entityToId, relationToId, validTriples, testTriples = data_paths["train"], data_paths["entity2id"], data_paths["relation2id"], data_paths["valid"], data_paths["test"]
        entity_set, relation_set, triple_list, valid_triple_list = TransE_pytorch.dataloader(trainTriples, entityToId, relationToId, validTriples)
        csv_filePath = "param.csv"
        fig_path = f"{dataset}_torch_TransE_loss_plot.png"
        entityEmbRes = f"{dataset}_torch_TransE_entity_{embedding_size}dim_batch{batch_size}"
        relationEmbRes = f"{dataset}_torch_TransE_relation_{embedding_size}dim_batch{batch_size}"
        transE = TransE_pytorch.TransE(entity_set, relation_set, triple_list, embedding_dim=embedding_size, lr=lr_rate, margin=6.0,
                        norm=1, C=0.25,
                        valid_triple_list=valid_triple_list)
        transE.data_initialise()
        st.markdown("## **Check & Download results**")
        st.success('-------------------------Start Training------------------------')
        df = transE.training_run(epochs=epoch_nums, batch_size=batch_size, out_file_title=f"{dataset}_torch_")
        df.to_csv("param.csv")
        if testFlage == True:
            st.success('-------------------------Start Testing------------------------')
            transE.insert_test_data(entityEmbRes, relationEmbRes, testTriples)
            raw_hit_10, raw_mean_rank = transE.test_run(filter=False)
            filtered_hit_10, filtered_mean_rank = transE.test_run(filter=True)

        st.success('-------------------------ğŸ˜ŠğŸ˜ŠBelows are resultsğŸ˜ŠğŸ˜Š------------------------')
        params_show(csv_filePath)
        loss_plot(fig_path)
        if raw_hit_10 and raw_mean_rank and filtered_mean_rank and filtered_hit_10:
            test_metric_show(raw_mean_rank,raw_hit_10,filtered_mean_rank,filtered_hit_10)
        zipObj = ZipFile("results.zip","w")
        zipObj.write(entityEmbRes)
        zipObj.write(relationEmbRes)
        zipObj.close()
        ZipfileDotZip = "results.zip"
        zip_download_button(ZipfileDotZip)

        st.success(f"Please use above button to download embedding result~")
        st.success("---------------------------END----------------------------")

# å¦‚æœæ˜¯TransHç®—æ³•ï¼š
    if algorithm_selection == "TransH":
        data_paths = ds_selection(dataset)
        batch_size = batchSize_selection(dataset)
        embedding_dim = embedding_size
        trainTriples, entityToId, relationToId, validTriples, testTriples = data_paths["train"], data_paths[
                "entity2id"], data_paths["relation2id"], data_paths["valid"], data_paths["test"]
        entity_set, relation_set, triple_list, valid_triple_list = TransH_pytorch.dataloader(trainTriples,
                                                                                                 entityToId,
                                                                                                 relationToId,
                                                                                                 validTriples)
        csv_filePath = "param.csv"
        fig_path = f"{dataset}_torch_TransH_loss_plot.png"
        entityEmbRes = f"{dataset}_torch_TransH_entity_{embedding_dim}dim_batch{batch_size}"
        normRelations = f"{dataset}_torch_TransH_norm_relations_{embedding_dim}dim_batch{batch_size}"
        hyperRelations = f"{dataset}_torch_TransH_hyper_relations_{embedding_dim}dim_batch{batch_size}"
        lossRecord = f"{dataset}_torch_loss_record.txt"
        transH = TransH_pytorch.TransH(entity_set, relation_set, triple_list, embedding_dim=embedding_dim,
                                           lr=lr_rate, margin=8.0, norm=1, C=1.0, epsilon=1e-5,
                                           valid_triple_list=valid_triple_list)
        transH.data_initialise()
        st.markdown("## **Check & Download results**")
        st.success('-------------------------Start Training------------------------')
        df = transH.training_run(epochs=epoch_nums, batch_size=batch_size, out_file_title=f"{dataset}_torch_")
        df.to_csv("param.csv")
        if testFlage == True:
            st.success('-------------------------Start Testing------------------------')
            transH.insert_data(entityEmbRes, normRelations, hyperRelations, testTriples, lossRecord)
            raw_hit_10, raw_mean_rank = transH.test_run(filter=False)
            filtered_hit_10, filtered_mean_rank = transH.test_run(filter=True)

        st.success('-------------------------ğŸ˜ŠğŸ˜ŠBelows are resultsğŸ˜ŠğŸ˜Š------------------------')
        params_show(csv_filePath)
        loss_plot(fig_path)
        if raw_hit_10 and raw_mean_rank and filtered_mean_rank and filtered_hit_10:
            test_metric_show(raw_mean_rank, raw_hit_10, filtered_mean_rank, filtered_hit_10)
        zipObj = ZipFile("results.zip", "w")
        zipObj.write(entityEmbRes)
        zipObj.write(normRelations)
        zipObj.write(hyperRelations)
        zipObj.close()
        ZipfileDotZip = "results.zip"
        zip_download_button(ZipfileDotZip)

        st.success(f"Please use above button to download embedding result~")
        st.success("---------------------------END----------------------------")

# å¦‚æœæ˜¯TransRç®—æ³•
    if algorithm_selection == "TransR":
        data_paths = ds_selection(dataset)
        batch_size = batchSize_selection(dataset)
        entity_embedding_dim = embedding_size
        relation_embedding_dim = embedding_size
        trainTriples, entityToId, relationToId, validTriples, testTriples = data_paths["train"], data_paths["entity2id"], data_paths["relation2id"], data_paths["valid"], data_paths["test"]
        entity_set, relation_set, triple_list, valid_triple_list = TransR_pytorch.dataloader(trainTriples, entityToId, relationToId, validTriples)
        csv_filePath = "param.csv"
        fig_path = f"{dataset}_torch_TransR_loss_plot.png"
        entityEmbRes = f"{dataset}_torch_TransR_entity_{embedding_size}dim_batch{batch_size}"
        relationEmbRes = f"{dataset}_torch_TransR_relation_{embedding_size}dim_batch{batch_size}"
        rel_matrix = f"{dataset}_torch_TransR_rel_matrix_{entity_embedding_dim}_{relation_embedding_dim}dim_batch{batch_size}"
        transR = TransR_pytorch.TransR(entity_set, relation_set, triple_list, ent_dim=entity_embedding_dim, rel_dim=relation_embedding_dim, lr=lr_rate, margin=6.0,
                                 norm=1, C=0.25, valid_triples=valid_triple_list)
        transR.data_initialise()
        st.markdown("## **Check & Download results**")
        st.success('-------------------------Start Training------------------------')
        df = transR.training_run(epochs=epoch_nums, batch_size=batch_size, out_file_title=f"{dataset}_torch_")
        df.to_csv("param.csv")
        if testFlage == True:
            st.success('-------------------------Start Testing------------------------')
            transR.insert_test_data(entityEmbRes, relationEmbRes, rel_matrix,testTriples)
            raw_hit_10, raw_mean_rank = transR.test_run(filter=False)
            filtered_hit_10, filtered_mean_rank = transR.test_run(filter=True)

        st.success('-------------------------ğŸ˜ŠğŸ˜ŠBelows are resultsğŸ˜ŠğŸ˜Š------------------------')
        params_show(csv_filePath)
        loss_plot(fig_path)
        if raw_hit_10 and raw_mean_rank and filtered_mean_rank and filtered_hit_10:
            test_metric_show(raw_mean_rank,raw_hit_10,filtered_mean_rank,filtered_hit_10)
        zipObj = ZipFile("results.zip", "w")
        zipObj.write(entityEmbRes)
        zipObj.write(relationEmbRes)
        zipObj.write(rel_matrix)
        zipObj.close()
        ZipfileDotZip = "results.zip"
        zip_download_button(ZipfileDotZip)

        st.success(f"Please use above button to download embedding result~")
        st.success("---------------------------END----------------------------")

# å¦‚æœæ˜¯TransDç®—æ³•ï¼š
    if algorithm_selection == "TransD":
        data_paths = ds_selection(dataset)
        batch_size = batchSize_selection(dataset)
        entity_embedding_dim = embedding_size
        relation_embedding_dim = embedding_size
        trainTriples, entityToId, relationToId, validTriples, testTriples = data_paths["train"], data_paths["entity2id"], data_paths["relation2id"], data_paths["valid"], data_paths["test"]
        entity_set, relation_set, triple_list, valid_triple_list = TransD_pytorch.dataloader(trainTriples, entityToId, relationToId, validTriples)
        csv_filePath = "param.csv"
        fig_path = f"{dataset}_torch_TransD_loss_plot.png"
        entityEmbRes = f"{dataset}_torch_TransD_entity_{embedding_size}dim_batch{batch_size}"
        relationEmbRes = f"{dataset}_torch_TransD_relation_{embedding_size}dim_batch{batch_size}"
        entity_transfer = f"{dataset}_torch_TransD_ent_transfer_{entity_embedding_dim}_{relation_embedding_dim}dim_batch{batch_size}"
        relation_transfer = f"{dataset}_torch_TransD_rel_transfer_{entity_embedding_dim}_{relation_embedding_dim}dim_batch{batch_size}"
        transD = TransD_pytorch.TransD(entity_set, relation_set, triple_list, embedding_dim=entity_embedding_dim, lr=lr_rate, margin=4.0, norm=1, C = 0.25, valid_triple_list=valid_triple_list)
        transD.data_initialise()
        st.markdown("## **Check & Download results**")
        st.success('-------------------------Start Training------------------------')
        df = transD.training_run(epochs=epoch_nums, batch_size=batch_size, out_file_title=f"{dataset}_torch_")
        df.to_csv("param.csv")
        if testFlage == True:
            st.success('-------------------------Start Testing------------------------')
            transD.insert_test_data(entityEmbRes, relationEmbRes, relation_transfer, entity_transfer,testTriples)
            raw_hit_10, raw_mean_rank = transD.test_run(filter=False)
            filtered_hit_10, filtered_mean_rank = transD.test_run(filter=True)

        st.success('-------------------------ğŸ˜ŠğŸ˜ŠBelows are resultsğŸ˜ŠğŸ˜Š------------------------')
        params_show(csv_filePath)
        loss_plot(fig_path)
        if raw_hit_10 and raw_mean_rank and filtered_mean_rank and filtered_hit_10:
            test_metric_show(raw_mean_rank,raw_hit_10,filtered_mean_rank,filtered_hit_10)
        zipObj = ZipFile("results.zip", "w")
        zipObj.write(entityEmbRes)
        zipObj.write(relationEmbRes)
        zipObj.write(entity_transfer)
        zipObj.write(relation_transfer)
        zipObj.close()
        ZipfileDotZip = "results.zip"
        zip_download_button(ZipfileDotZip)

        st.success(f"Please use above button to download embedding result~")
        st.success("---------------------------END----------------------------")

























